{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab289fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: <module 'torch.version' from '/usr/local/lib/python3.10/dist-packages/torch/version.py'>\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.version}\")\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e2cb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1053, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3314/580496701.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset  # Example: HuggingFace Datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb66a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer  # Updated imports\n",
    "import torch.nn as nn\n",
    "\n",
    "# Tokenizer and Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "legal_bert = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "\n",
    "# Model Definition\n",
    "class LegalBERT_BiGRU(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.legal_bert = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")  # Updated\n",
    "        self.bigru = nn.GRU(\n",
    "            input_size=768,\n",
    "            hidden_size=128,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.classifier = nn.Linear(128 * 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.legal_bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        gru_out, _ = self.bigru(last_hidden_state)\n",
    "        logits = self.classifier(gru_out[:, -1, :])\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a57800",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LegalBERT_BiGRU(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c386f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Police covertly installed CCTV cameras in a suspect's home for 6 months without judicial approval. The applicant \n",
    "argued this breached Article 8 (right to privacy). The government admitted the surveillance lacked proper \n",
    "authorization but claimed it was necessary to combat organized crime.\n",
    "\"\"\"\n",
    "sample_label = 0  # 1 = \"violation\", 0 = \"no violation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4dfeff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    sample_text, \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    max_length=512, \n",
    "    return_tensors=\"pt\"\n",
    ").to(device)  # Move to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a71c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: No Violation\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "    pred = torch.argmax(logits).item()\n",
    "\n",
    "print(\"Predicted:\", \"Violation\" if pred == 1 else \"No Violation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e7b381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts\n",
    "def tokenize(texts, max_len=512):\n",
    "    return tokenizer(\n",
    "        texts, \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=max_len, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc84dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Split data into train/test\u001b[39;00m\n\u001b[1;32m      4\u001b[0m train_texts, test_texts, train_labels, test_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtexts\u001b[49m, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Tokenize the texts\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(texts, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train/test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "test_encodings = tokenize(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0322b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LegalDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = LegalDataset(train_encodings, train_labels)\n",
    "test_dataset = LegalDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825977b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[1;32m      2\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, dataloader, optimizer, loss_fn, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "train(model, train_loader, optimizer, loss_fn, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5782dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs)\n",
    "    pred = torch.argmax(logits).item()\n",
    "    return \"Violation\" if pred == 1 else \"No Violation\"\n",
    "\n",
    "# Example\n",
    "case_text = \"The applicant alleged a violation of Article 6 of the Convention...\"\n",
    "print(predict(case_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
